{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Payback Prediction - Ensemble Model (XGBoost + Logistic Regression)\n",
    "\n",
    "## Goal\n",
    "Predict the probability that a borrower will pay back their loan using an ensemble of XGBoost and Logistic Regression models. We will perform hyperparameter tuning for both models and combine them using a Voting Classifier.\n",
    "\n",
    "## Steps\n",
    "1.  Data Loading\n",
    "2.  Feature Engineering\n",
    "3.  Hyperparameter Tuning (RandomizedSearchCV)\n",
    "4.  Ensemble Modeling (VotingClassifier)\n",
    "5.  Model Evaluation (Stratified K-Fold CV)\n",
    "6.  Submission Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (593994, 13)\n",
      "Test shape: (254569, 12)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Train shape: (593994, 26)\n",
      "Processed Test shape: (254569, 26)\n"
     ]
    }
   ],
   "source": [
    "# Combine for consistent encoding\n",
    "train_df['is_train'] = 1\n",
    "test_df['is_train'] = 0\n",
    "test_df['loan_paid_back'] = np.nan\n",
    "\n",
    "full_df = pd.concat([train_df, test_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "# 1. Log Transformation for skewed features\n",
    "skewed_features = ['annual_income', 'loan_amount', 'debt_to_income_ratio']\n",
    "for col in skewed_features:\n",
    "    full_df[col] = np.log1p(full_df[col])\n",
    "\n",
    "# 2. Ordinal Encoding for grade_subgrade\n",
    "grades = sorted(full_df['grade_subgrade'].unique())\n",
    "grade_map = {grade: i for i, grade in enumerate(grades)}\n",
    "full_df['grade_subgrade_encoded'] = full_df['grade_subgrade'].map(grade_map)\n",
    "\n",
    "# 3. One-Hot Encoding for other categoricals\n",
    "categorical_cols = ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose']\n",
    "full_df = pd.get_dummies(full_df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Drop original grade_subgrade and id\n",
    "full_df.drop(['grade_subgrade', 'id'], axis=1, inplace=True)\n",
    "\n",
    "# Split back\n",
    "train_processed = full_df[full_df['is_train'] == 1].drop(['is_train'], axis=1)\n",
    "test_processed = full_df[full_df['is_train'] == 0].drop(['is_train', 'loan_paid_back'], axis=1)\n",
    "\n",
    "X = train_processed.drop('loan_paid_back', axis=1)\n",
    "y = train_processed['loan_paid_back']\n",
    "X_test = test_processed\n",
    "\n",
    "print(f\"Processed Train shape: {X.shape}\")\n",
    "print(f\"Processed Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning XGBoost...\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best XGBoost Params: {'subsample': 0.8, 'scale_pos_weight': np.float64(0.25184723094496453), 'n_estimators': 3000, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.9}\n",
      "Best XGBoost Score: 0.9215151916463705\n"
     ]
    }
   ],
   "source": [
    "# Calculate scale_pos_weight for XGBoost\n",
    "num_pos = y.sum()\n",
    "num_neg = len(y) - num_pos\n",
    "scale_pos_weight = num_neg / num_pos\n",
    "\n",
    "# --- XGBoost Tuning ---\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    tree_method='hist' # Faster training\n",
    ")\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [1000, 2000, 3000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'scale_pos_weight': [1, scale_pos_weight]\n",
    "}\n",
    "\n",
    "# Using RandomizedSearchCV for speed\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    xgb_clf,\n",
    "    param_distributions=xgb_params,\n",
    "    n_iter=5, # Limited iterations for demonstration speed\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Tuning XGBoost...\")\n",
    "xgb_search.fit(X, y)\n",
    "print(f\"Best XGBoost Params: {xgb_search.best_params_}\")\n",
    "print(f\"Best XGBoost Score: {xgb_search.best_score_}\")\n",
    "best_xgb = xgb_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning Logistic Regression...\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best LR Params: {'lr__penalty': 'l1', 'lr__C': 0.01}\n",
      "Best LR Score: 0.9102459889557615\n"
     ]
    }
   ],
   "source": [
    "# --- Logistic Regression Tuning ---\n",
    "# Logistic Regression needs Scaling and Imputation\n",
    "lr_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LogisticRegression(solver='saga', max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "lr_params = {\n",
    "    'lr__C': [0.01, 0.1, 1, 10],\n",
    "    'lr__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "lr_search = RandomizedSearchCV(\n",
    "    lr_pipeline,\n",
    "    param_distributions=lr_params,\n",
    "    n_iter=5,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nTuning Logistic Regression...\")\n",
    "lr_search.fit(X, y)\n",
    "print(f\"Best LR Params: {lr_search.best_params_}\")\n",
    "print(f\"Best LR Score: {lr_search.best_score_}\")\n",
    "best_lr = lr_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ensemble Modeling (VotingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', best_xgb),\n",
    "        ('lr', best_lr)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation (Stratified K-Fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble CV ROC AUC Scores: [0.92206032 0.92164786 0.9196514  0.92046015 0.92034931]\n",
      "Average Ensemble CV ROC AUC: 0.92083 +/- 0.00089\n"
     ]
    }
   ],
   "source": [
    "FOLDS = 5\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(ensemble_clf, X, y, cv=skf, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "print(f\"Ensemble CV ROC AUC Scores: {cv_scores}\")\n",
    "print(f\"Average Ensemble CV ROC AUC: {np.mean(cv_scores):.5f} +/- {np.std(cv_scores):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Submission Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining ensemble on full data...\n",
      "Submission saved to submission_ensemble.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loan_paid_back</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593994</td>\n",
       "      <td>0.861872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>593995</td>\n",
       "      <td>0.935717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>593996</td>\n",
       "      <td>0.165388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593997</td>\n",
       "      <td>0.817991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593998</td>\n",
       "      <td>0.914520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  loan_paid_back\n",
       "0  593994        0.861872\n",
       "1  593995        0.935717\n",
       "2  593996        0.165388\n",
       "3  593997        0.817991\n",
       "4  593998        0.914520"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on full training data\n",
    "print(\"Retraining ensemble on full data...\")\n",
    "ensemble_clf.fit(X, y)\n",
    "\n",
    "# Predict on test set\n",
    "test_preds = ensemble_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'loan_paid_back': test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_ensemble.csv', index=False)\n",
    "print(\"Submission saved to submission_ensemble.csv\")\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
